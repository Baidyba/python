{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82edc5b2",
   "metadata": {},
   "source": [
    "# Étape 1 : Importer les bibliothèques requises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc895b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2           ##cv2 est la bibliothèque OpenCV, qui est utilisée pour le traitement des images et des vidéos. \n",
    "import streamlit as st\n",
    " ## streamlit est une bibliothèque pour créer des applications Web interactives avec Python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbcf2c4d",
   "metadata": {},
   "source": [
    "# Étape 2 : Charger le classificateur de cascade de visages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03e10746",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659714c2",
   "metadata": {},
   "source": [
    "# Étape 3 : Créer une fonction pour capturer les images de la webcam et détecter les visages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ccf7ec67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_faces():\n",
    "    # Initialize the webcam\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    while True:\n",
    "        # Read the frames from the webcam\n",
    "        ret, frame = cap.read()\n",
    "        # Convert the frames to grayscale\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        # Detect the faces using the face cascade classifier\n",
    "        faces = face_cascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5)\n",
    "        \n",
    "        # Draw rectangles around the detected faces\n",
    "        for (x, y, w, h) in faces:\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        # Display the frames\n",
    "        cv2.imshow('Face Detection using Viola-Jones Algorithm', frame)\n",
    "        # Exit the loop when 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    # Release the webcam and close all windows\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8766d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import streamlit as st\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default .xml')\n",
    "def detect_faces():\n",
    "    # Initialize the webcam\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    while True:\n",
    "        # Read the frames from the webcam\n",
    "        _, frame = cap.read()\n",
    "        # Convert the frames to grayscale\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
    "        # Detect the faces using the face cascade classifier\n",
    "        faces = face_cascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5)\n",
    "        # Draw rectangles around the detected faces\n",
    "        for (x, y, w, h) in faces:\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        # save face\n",
    "        # cv2.imwrite(\"image_detections.jpg\", frame)\n",
    "        # st.write(\"Image enregistrée avec les visages détectés.\")\n",
    "        # Display the frames\n",
    "        cv2.imshow('Face Detection using Viola-Jones Algorithm', frame)\n",
    "        # Exit the loop when 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    # Release the webcam and close all windows\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def app():\n",
    "    st.title(\"Face Detection using Viola-Jones Algorithm\")\n",
    "    st.write(\"Press the button below to start detecting faces from your webcam\")\n",
    "    # Add a button to start detecting faces\n",
    "    if st.button(\"Detect Faces\"):\n",
    "        # Call the detect_faces function\n",
    "        detect_faces()\n",
    "if __name__ == \"__main__\":\n",
    "    app()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9adf7a58",
   "metadata": {},
   "source": [
    "# Étape 4 : Définir l'application Streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfc79fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-06 20:10:31.140 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run C:\\Users\\Hp\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    }
   ],
   "source": [
    "def app():      ##La fonction app() définit l'application Streamlit\n",
    "    st.title(\"Face Detection using Viola-Jones Algorithm\")\n",
    "    st.write(\"Press the button below to start detecting faces from your webcam\")\n",
    "    \n",
    "    # Ajouter un bouton pour commencer à détecter les visages\n",
    "    \n",
    "if st.button(\"Detect Faces\"):\n",
    "            \n",
    "            # Call the detect_faces function\n",
    "            \n",
    "              detect_faces()\n",
    "if __name__ == \"__main__\":\n",
    "    app()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800bbc5b",
   "metadata": {},
   "source": [
    "# Amélioration de l'application Streamlit pour la détection de visage à l'aide de l'algorithme Viola-Jones de l'exemple du contenu¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9eb80a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ajoutez des instructions à l'interface de l'application Streamlit pour guider l'utilisateur sur la façon d'utiliser l'application.\n",
    "#Utilisez les fonctions st.write() ou st.markdown() pour ajouter des instructions à l'interface\n",
    "\n",
    "import streamlit as st\n",
    "\n",
    "# Instructions pour l'utilisateur\n",
    "st.write(\"Instructions\")\n",
    "st.write(\"1. Téléchargez une image contenant des visages.\")\n",
    "st.write(\"2. Utilisez les paramètres pour ajuster la détection des visages.\")\n",
    "st.write(\"3. Cliquez sur le bouton 'Détecter les visages' pour afficher les résultats.\")\n",
    "st.write(\"4. Utilisez le sélecteur de couleur pour choisir la couleur des rectangles.\")\n",
    "st.write(\"5. Utilisez le bouton 'Enregistrer l'image' pour enregistrer l'image avec les visages détectés.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc58a5b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-06 22:28:02.155 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run C:\\Users\\Hp\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    }
   ],
   "source": [
    "#Ajoutez une fonctionnalité pour enregistrer les images avec les visages détectés sur l'appareil de l'utilisateur.\n",
    "#Utilisez la fonction cv2.imwrite() pour enregistrer les images.\n",
    "cap = cv2.VideoCapture(0)\n",
    "    \n",
    "        # Read the frames from the webcam\n",
    "ret, frame = cap.read()\n",
    "import cv2\n",
    "\n",
    "cv2.imwrite(\"image_detections.jpg\",frame)\n",
    "st.write(\"Image enregistrée avec les visages détectés.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5da91fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Ajoutez une fonctionnalité pour permettre à l'utilisateur de choisir la couleur des rectangles dessinés autour des visages détectés.\n",
    "\n",
    "color = st.color_picker(\"Choisissez une couleur\", \"#00F900\")\n",
    "st.write('The current color is', color)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088d27f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
